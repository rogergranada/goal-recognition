# Training Faster-rcnn.pytorch Using KSCGR Dataset

This file contains information for training `Faster-RCNN.pytorch` using the [KSCGR](http://www.murase.m.is.nagoya-u.ac.jp/KSCGR/) dataset. 

## Downloading KSCGR dataset

Before creating any file, we have to download the dataset from its [original site](http://www.murase.m.is.nagoya-u.ac.jp/KSCGR/download.html). 

## Creating structure for KSCGR dataset

In order to deal with KSCGR dataset using Faster R-CNN, we have to convert the initial structure of folders of KSCGR to the VOC structure that contains all images into a single folder. To do that, we create the structure under the `$ROOT_DATA/data/` folder. The folder containing the structure is named `KSCGR` and inside it, we have `Annotation` - with all XMLs containing annotations, `ImageSets` - with all splits of the dataset, and `JPEGImages` - with all images of the dataset. To create this structure we run:

```
$ cd $ROOT_DATA/data/
$ mkdir KSCGR
$ cd KSCGR/
$ mkdir Annotations ImageSets
$ echo "" >> $FRCN_ROOT/.envrc
$ echo "#Annotations ImageSet and JPEGImages folders" >> $FRCN_ROOT/.envrc
$ echo "export Annotation=${ROOT_DATA}/data/KSCGR/Annotations" >> $FRCN_ROOT/.envrc
$ echo "export ImageSets=${ROOT_DATA}/data/KSCGR/ImageSets" >> $FRCN_ROOT/.envrc
$ echo "export JPEGImages=${ROOT_DATA}/data/KSCGR/JPEGImages" >> $FRCN_ROOT/.envrc
$ echo "" >> $FRCN_ROOT/.envrc
```

## Merging LIS annotation files:

Having a folder `Annotation` with all LIS files containing labels and bounding boxes annotated, merge all those files using a single dictionary to keep track of all ids and labels. The input to the script is the folder containing all annotated files (e.g., `data1-boild_egg.txt`, `data1-ham_egg.txt`, `data1-kinshi_egg.txt`, ..., `data5-scrambled_egg.txt`) and outputs a `lis_merged.txt` file containing the concatenation of all annotations. To run this script, use:

```
$ python merge_lis_annotation.py /home/roger/Desktop/Annotation/
```

---------------------------------------------------------------------------------------------------------
## Create a folder containing ALL images

Before training our network, we have to create a folder named `JPEGImages` containing all images of our dataset. As KSCGR separate images in folders representing videos, we have to copy all these images to a single folder and map each original file to the new named file in `JPEGImages`. To do that, we run:

```
$ python kscgr2voc_dataset.py /usr/share/datasets/KSCGR/paths.txt $JPEGImages
```

This script copies all the images to a single folder and creates a file `map_paths.txt` with the mapping between the original and the new folders. Now, we have all files in `JPEGImages` folder, we can create a link in `data` folder using:

```
$ cd $FRCN_ROOT/data
$ ln -s $ROOT_DATA/data/KSCGR/ KSCGR
```

Thus, we can access our data folder from inside our project.
---------------------------------------------------------------------------------------------------------
## Convert LIS paths to VOC paths

Now we have all annotated files in a single plain text file, we have to change the LIS paths based on KSCGR to the VOC paths based on a sing folder for all images. We can do it by using the `map_paths.txt` generated by `kscrg2voc_dataset.py`, which copies all image files to a single folder, creating a mapping between the original files and the new ones. In order to convert the LIS paths to the new VOC paths, use:

```
$ python kscgr2voc_annotation.py /home/roger/Desktop/Annotation/lis_merged.txt /home/roger/Desktop/Annotation/map_paths.txt
```

This command generates a file named `voc_paths.txt` in the `Annotation` folder.

---------------------------------------------------------------------------------------------------------
## Create VOC annotation XML files

Having all files with the correct paths, we can create the XML files containing the VOC annotation in folder `data/KSCGR/Annotations` using the command:

```
$ python lis2voc.py $FRCN_ROOT/data/KSCGR/voc_paths.txt $FRCN_ROOT/data/KSCGR/Annotations
```

This command populates our `Annotations` folder with a XML file for each image containing all objects described in ground truth.

=========================================================================================================
# Training using KSCGR dataset

```
$ CUDA_VISIBLE_DEVICES=0 python trainval_net.py --dataset kscgr --net vgg16 --bs 4 --nw 1 --lr 0.01 --lr_decay_step 5 --cuda --use_tfb
$ CUDA_VISIBLE_DEVICES=0 python trainval_net.py --dataset kscgr --net res101 --bs 4 --nw 1 --lr 0.01 --lr_decay_step 8 --epochs 10 --cuda --use_tfb
```

=========================================================================================================
# Check loss using tensorboard

In order to verify the loss, you have to run the `trainval_net.py` file using the option `--use_tfb`. In case saving logs, in $FRCN_ROOT, run:

```
$ tensorboard --logdir="./logs" --port 6006
```

In the browser, you call tensorboard as:

```
http://localhost:6006
```


=========================================================================================================
# Testing DEMO

In order to test `demo.py`, first we have to edit the file `$FRCN_ROOT/lib/model/utils/config.py`, editing the line 292 by adding the anchor scale `4` as:

```
__C.ANCHOR_SCALES = [4,8,16,32]
```

Then, we edit the file `demo.py` modifying the `pascal_classes` variable, adding the classes of our dataset as:

```
pascal_classes = np.asarray(['__background__',  # always index 0
         'person', 'egg', 'beaten egg', 'boiled egg', 'egg crepe', 'ham egg', 
         'kinshi egg', 'scramble egg', 'omelette', 'ham', 'pan', 'frying pan', 
         'pan handle', 'pan lid', 'bowl', 'cutting board', 'dishcloth',
         'glass', 'hashi', 'knife', 'milk carton', 'oil bottle', 'plate', 
         'saltshaker', 'spoon', 'turner'])
```

Now, we are ready to run the demo, where images to be tested are inside the `$FRCN_ROOT/images` folder. We run the command:

```
$ CUDA_VISIBLE_DEVICES=1 python demo.py --dataset kscgr --net res101 --checksession 1 --checkepoch 10 --checkpoint 85672 --cuda  --load_dir /home/roger/Workspace/faster-rcnn.pytorch/models

```
